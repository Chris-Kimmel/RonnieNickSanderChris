{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some rough code I used to check whether all the json files had the same structure.\n",
    "\n",
    "The code shows that, except for midterm-2018_processed_user_objects, all the json files have more or less the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All the json files should be dictionary. One of its keys should be 'user'.\n",
    "And 'user' should map to another dictionary with tons of keys.\n",
    "Mostly this script is checking that the every 'user' dictionary has the same keys.\n",
    "'''\n",
    "known_inconsistent_keys = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # for reading json files\n",
    "import os # for reading directory contents\n",
    "from pathlib import Path\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\botometer-feedback-2019_tweets.json\n",
      "data\\botwiki-2019_tweets.json\n",
      "data\\celebrity-2019_tweets.json\n",
      "data\\cresci-rtbust-2019_tweets.json\n",
      "data\\cresci-stock-2018_tweets.json\n",
      "data\\gilani-2017_tweets.json\n",
      "data\\midterm-2018_processed_user_objects.json\n",
      "data\\political-bots-2019_tweets.json\n",
      "data\\pronbots-2019_tweets.json\n",
      "data\\vendor-purchased-2019_tweets.json\n",
      "data\\verified-2019_tweets.json\n"
     ]
    }
   ],
   "source": [
    "# list the paths of all files in the data directory\n",
    "data_path = Path('data') # this is just a path TO the data directory\n",
    "data_files_to_compare = [Path.joinpath(data_path,filename) for filename in os.listdir('./data/') if filename.endswith('.json')]\n",
    "\n",
    "for x in data_files_to_compare:\n",
    "    print(x)\n",
    "\n",
    "json_contents = dict()\n",
    "for path in data_files_to_compare:\n",
    "    with open(path, 'r') as file:\n",
    "        json_contents[path] = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_contents.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_archetype = json_contents[list(json_contents.keys())[0]]\n",
    "key_set_archetype = set(json_archetype[0]['user'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, each json file is a list of many accounts.\n",
    "Each account is a dictionary with two keys: 'created_at' and 'user'\n",
    "The value of the 'user' entry of that dictionary is itself a dictionary with many keys.\n",
    "\n",
    "In the following code, we check to make sure that all the json files have this structure.\n",
    "We also examine the keys of the 'user' dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this json dataset was formatted as expected\n",
      "data\\botometer-feedback-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\botwiki-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\celebrity-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\cresci-rtbust-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\cresci-stock-2018_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\gilani-2017_tweets.json\n",
      "\n",
      "something's weird about this particular json dataset\n",
      "data\\midterm-2018_processed_user_objects.json\n",
      "entry = {'probe_timestamp': 'Tue Nov 06 20:35:08 2018', 'user_id': 4107317134, 'screen_name': 'danitheduck21', 'name': 'Daniüè≥Ô∏è\\u200düåà', 'description': 'Dani üíú She/Her üíú Randomness all over. Expect lots of politics, Soap talk, LGBT content, and lots of TV shows üíú #AmberRiley #Klaine #JaSam #Clana', 'user_created_at': 'Tue Nov 03 21:16:13 2015', 'url': None, 'lang': 'en', 'protected': False, 'verified': False, 'geo_enabled': False, 'profile_use_background_image': False, 'default_profile': False, 'followers_count': 481, 'friends_count': 870, 'listed_count': 26, 'favourites_count': 6542, 'statuses_count': 67025, 'tid': 1059907055421509632}\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\political-bots-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\pronbots-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\vendor-purchased-2019_tweets.json\n",
      "\n",
      "this json dataset was formatted as expected\n",
      "data\\verified-2019_tweets.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weird_datasets = list()\n",
    "for file_path in json_contents.keys():\n",
    "    json_obj = json_contents[file_path]\n",
    "    # file_path is the filepath of the json file\n",
    "    # json_obj is the contents of the json file\n",
    "    \n",
    "    assert(type(json_obj) == list) # the json object should be a list of accounts\n",
    "    try:\n",
    "        # make sure each acccount is structured in the same basic way\n",
    "        for entry in json_obj:\n",
    "            assert(type(entry) == dict), f'entry is wrong type: {type(entry)}'\n",
    "            assert(len(entry) == 2), f'entry = {entry}'\n",
    "            assert(set(entry.keys()) == {'created_at', 'user'}), f'entry keys {set(entry.keys())}'\n",
    "            assert(type(entry['created_at']) == str), type(entry['created_at'])\n",
    "            assert(type(entry['created_at']) == str), type(entry['created_at'])\n",
    "    except Exception as e:\n",
    "        weird_datasets.append(file_path)\n",
    "        print('something\\'s weird about this particular json dataset')\n",
    "        print(file_path) # print the filepath of this weird dataset\n",
    "        print(e)\n",
    "        print()\n",
    "        continue\n",
    "    \n",
    "    # If the above try-catch statement failed, the program goes to the next json file\n",
    "    # and doesn't execute any code below. If the try-catch statement succeeded, we\n",
    "    # should print something to let us know.\n",
    "    print('this json dataset was formatted as expected')\n",
    "    print(file_path)\n",
    "    print()\n",
    "    \n",
    "    # What if the account data for different accounts includes different keys?\n",
    "    # Let's collect only the keys that are the same for every user\n",
    "    agreed_keys = reduce( lambda x,y : x & y , [entry['user'].keys() for entry in json_obj] )\n",
    "    \n",
    "    # Now let's figure out which keys are NOT the same for every user\n",
    "    all_keys = reduce( lambda x,y : x | y , [entry['user'].keys() for entry in json_obj] )\n",
    "    disagreed_keys = all_keys - agreed_keys\n",
    "\n",
    "    # Let's keep a running collection of all the disagreed keys across all json files\n",
    "    known_inconsistent_keys = known_inconsistent_keys | disagreed_keys\n",
    "    \n",
    "    # Let's also include any differences between key_set_archetype and all_keys\n",
    "    known_inconsistent_keys = known_inconsistent_keys | (all_keys ^ key_set_archetype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we find comparing the structures of all the json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the keys that are present for some accounts and datasets, but absent for others:\n",
      "profile_banner_url\n",
      "withheld_in_countries\n",
      "\n",
      "Except for these datasets...\n",
      "data\\midterm-2018_processed_user_objects.json\n",
      "...all datasets have these keys\n",
      "profile_sidebar_border_color\n",
      "name\n",
      "profile_background_image_url\n",
      "listed_count\n",
      "favourites_count\n",
      "created_at\n",
      "followers_count\n",
      "friends_count\n",
      "profile_background_color\n",
      "id_str\n",
      "is_translation_enabled\n",
      "translator_type\n",
      "profile_use_background_image\n",
      "notifications\n",
      "is_translator\n",
      "profile_sidebar_fill_color\n",
      "utc_offset\n",
      "follow_request_sent\n",
      "default_profile\n",
      "id\n",
      "verified\n",
      "default_profile_image\n",
      "profile_text_color\n",
      "entities\n",
      "profile_background_tile\n",
      "protected\n",
      "profile_background_image_url_https\n",
      "location\n",
      "profile_image_url\n",
      "following\n",
      "lang\n",
      "geo_enabled\n",
      "time_zone\n",
      "profile_image_url_https\n",
      "profile_link_color\n",
      "url\n",
      "statuses_count\n",
      "screen_name\n",
      "has_extended_profile\n",
      "description\n",
      "contributors_enabled\n"
     ]
    }
   ],
   "source": [
    "print('These are the keys that are present for some accounts and datasets, but absent for others:')\n",
    "for x in known_inconsistent_keys: print(x)\n",
    "print()\n",
    "print('Except for these datasets...')\n",
    "for x in weird_datasets: print(str(x))\n",
    "print('...all datasets have these keys')\n",
    "for x in (key_set_archetype - known_inconsistent_keys): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the weird dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probe_timestamp': 'Tue Nov 06 20:35:08 2018',\n",
       " 'user_id': 4107317134,\n",
       " 'screen_name': 'danitheduck21',\n",
       " 'name': 'Daniüè≥Ô∏è\\u200düåà',\n",
       " 'description': 'Dani üíú She/Her üíú Randomness all over. Expect lots of politics, Soap talk, LGBT content, and lots of TV shows üíú #AmberRiley #Klaine #JaSam #Clana',\n",
       " 'user_created_at': 'Tue Nov 03 21:16:13 2015',\n",
       " 'url': None,\n",
       " 'lang': 'en',\n",
       " 'protected': False,\n",
       " 'verified': False,\n",
       " 'geo_enabled': False,\n",
       " 'profile_use_background_image': False,\n",
       " 'default_profile': False,\n",
       " 'followers_count': 481,\n",
       " 'friends_count': 870,\n",
       " 'listed_count': 26,\n",
       " 'favourites_count': 6542,\n",
       " 'statuses_count': 67025,\n",
       " 'tid': 1059907055421509632}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_timestamp\n",
      "user_id\n",
      "screen_name\n",
      "name\n",
      "description\n",
      "user_created_at\n",
      "url\n",
      "lang\n",
      "protected\n",
      "verified\n",
      "geo_enabled\n",
      "profile_use_background_image\n",
      "default_profile\n",
      "followers_count\n",
      "friends_count\n",
      "listed_count\n",
      "favourites_count\n",
      "statuses_count\n",
      "tid\n"
     ]
    }
   ],
   "source": [
    "display(json_contents[Path('data\\midterm-2018_processed_user_objects.json')][0])\n",
    "\n",
    "for x in json_contents[Path('data\\midterm-2018_processed_user_objects.json')][0].keys(): print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
